{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "badc7451-a345-4ac4-85c3-0b28ee1f96ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TensorFlow GPU Test ===\n",
      "TensorFlow version: 2.20.0\n",
      "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Built with CUDA: True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.test' has no attribute 'is_built_with_cudnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBuilt with CUDA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.test.is_built_with_cuda()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Check if built with cuDNN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBuilt with cuDNN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_built_with_cudnn\u001b[49m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# List all available devices\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll available devices:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'tensorflow._api.v2.test' has no attribute 'is_built_with_cudnn'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"=== TensorFlow GPU Test ===\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Check if GPU is available\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Check if built with CUDA\n",
    "print(f\"Built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "\n",
    "# Check if built with cuDNN\n",
    "print(f\"Built with cuDNN: {tf.test.is_built_with_cudnn()}\")\n",
    "\n",
    "# List all available devices\n",
    "print(\"\\nAll available devices:\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(f\"  - {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5139271-0755-4412-b3d9-1cdf257d2bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Detailed GPU Information ===\n",
      "✅ GPU(s) found!\n",
      "\n",
      "GPU 0:\n",
      "  Name: /physical_device:GPU:0\n",
      "  Device type: GPU\n",
      "  Details: {'compute_capability': (8, 9), 'device_name': 'NVIDIA GeForce RTX 4050 Laptop GPU'}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"=== Detailed GPU Information ===\")\n",
    "\n",
    "# Get all GPU devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"✅ GPU(s) found!\")\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"\\nGPU {i}:\")\n",
    "        print(f\"  Name: {gpu.name}\")\n",
    "        print(f\"  Device type: {gpu.device_type}\")\n",
    "        \n",
    "        # Get device details (if available)\n",
    "        try:\n",
    "            details = tf.config.experimental.get_device_details(gpu)\n",
    "            print(f\"  Details: {details}\")\n",
    "        except:\n",
    "            print(\"  Device details not available\")\n",
    "else:\n",
    "    print(\"❌ No GPU devices found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f5367f-e125-4ed5-8560-6a2022a11180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPU Performance Test ===\n",
      "Testing on CPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757702550.877400   42075 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3855 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-13 00:12:30.895822: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2025-09-13 00:12:31.025302: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2025-09-13 00:12:31.109708: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2025-09-13 00:12:31.247667: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2025-09-13 00:12:31.370156: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 400000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 3.6673 seconds\n",
      "Testing on GPU...\n",
      "GPU time: 0.1676 seconds\n",
      "Speedup: 21.89x faster!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "print(\"=== GPU Performance Test ===\")\n",
    "\n",
    "# Test on CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    print(\"Testing on CPU...\")\n",
    "    start_time = time.time()\n",
    "    a_cpu = tf.random.normal([10000, 10000])\n",
    "    b_cpu = tf.random.normal([10000, 10000])\n",
    "    c_cpu = tf.matmul(a_cpu, b_cpu)\n",
    "    cpu_time = time.time() - start_time\n",
    "    print(f\"CPU time: {cpu_time:.4f} seconds\")\n",
    "\n",
    "# Test on GPU (if available)\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    with tf.device('/GPU:0'):\n",
    "        print(\"Testing on GPU...\")\n",
    "        start_time = time.time()\n",
    "        a_gpu = tf.random.normal([10000, 10000])\n",
    "        b_gpu = tf.random.normal([10000, 10000])\n",
    "        c_gpu = tf.matmul(a_gpu, b_gpu)\n",
    "        gpu_time = time.time() - start_time\n",
    "        print(f\"GPU time: {gpu_time:.4f} seconds\")\n",
    "        print(f\"Speedup: {cpu_time/gpu_time:.2f}x faster!\")\n",
    "else:\n",
    "    print(\"No GPU available for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b58762-b020-447d-abc0-3732a3feb51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ GPU setup error: Physical devices cannot be modified after being initialized\n",
      "✅ Using float32 precision for stability\n",
      "🔍 Checking dataset availability...\n",
      "✅ Dataset already exists at: /home/rand-jadav/by_class/by_class\n",
      "🔍 Scanning byclass dataset...\n",
      "Scanned 1342017 valid images across 64 classes\n",
      "Found 1342017 images across 64 classes\n",
      "📥 Loading or creating model...\n",
      "📥 Loading pretrained model from: best_model_byclass_finetuned.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ new_classification (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ image (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ new_classification (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,743,552</span> (10.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,743,552\u001b[0m (10.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,739,200</span> (10.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,739,200\u001b[0m (10.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> (17.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,352\u001b[0m (17.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training samples: 1140745\n",
      "📊 Validation samples: 201272\n",
      "📊 Steps per epoch: 17824\n",
      "📊 Batch size: 64\n",
      "📊 Learning rate: 0.001\n",
      "\n",
      "🚀 Starting training...\n",
      "Testing data pipeline...\n",
      "Batch shape: (64, 128, 128, 1), Labels shape: (64,)\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13 13:47:44.281730: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_9}}\n",
      "E0000 00:00:1757751467.679902   27397 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_13_1/dropout_7_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  238/17824\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07:46\u001b[0m 436ms/step - accuracy: 0.3950 - loss: 0.2599"
     ]
    }
   ],
   "source": [
    "# emnist_byclass_finetune_optimized_4050.py\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import zipfile\n",
    "import tarfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# -----------------------\n",
    "# User config - OPTIMIZED for RTX 4050\n",
    "# -----------------------\n",
    "DATASET_DIR = \"/home/rand-jadav/by_class/by_class\"\n",
    "DATASET_ARCHIVE = \"/home/rand-jadav/Downloads/by.zip\"\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 64  # Increased batch size\n",
    "EPOCHS = 2\n",
    "VAL_SPLIT = 0.15\n",
    "RANDOM_SEED = 42\n",
    "SHUFFLE_BUFFER = 10000\n",
    "INVERT = True\n",
    "PRETRAINED_MODEL = \"best_model_byclass_finetuned.keras\"\n",
    "BEST_MODEL_PATH = \"best_model_byclass_finetuned.keras\"\n",
    "LABELMAP_JSON = \"byclass_labelmap.json\"\n",
    "\n",
    "VALID_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\", \".webp\", \".tiff\", \".tif\"}\n",
    "SUPPORTED_ARCHIVES = {\".zip\", \".tar\", \".gz\", \".bz2\", \".tar.gz\", \".tar.bz2\"}\n",
    "\n",
    "# =========================\n",
    "# GPU Memory Optimization\n",
    "# =========================\n",
    "def setup_gpu_memory():\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if not gpus:\n",
    "            print(\"ℹ️ No GPU detected, using CPU\")\n",
    "            return\n",
    "        \n",
    "        # Set memory growth first\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        # Then set memory limit if needed\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.set_logical_device_configuration(\n",
    "                    gpu,\n",
    "                    [tf.config.LogicalDeviceConfiguration(memory_limit=5120)]\n",
    "                )\n",
    "        except:\n",
    "            print(\"⚠️  Could not set memory limit, using memory growth only\")\n",
    "        \n",
    "        print(f\"✅ GPU configured: {len(gpus)} Physical GPU, {len(tf.config.list_logical_devices('GPU'))} Logical GPU\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ GPU setup error: {e}\")\n",
    "\n",
    "# =========================\n",
    "# Reproducibility\n",
    "# =========================\n",
    "def set_all_seeds(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "# =========================\n",
    "# Dataset scanning\n",
    "# =========================\n",
    "def scan_dataset_byclass(byclass_dir: str) -> Tuple[List[str], List[int], Dict[str, int], Dict[int, str]]:\n",
    "    filepaths = []\n",
    "    str_labels = []\n",
    "    byclass_path = Path(byclass_dir).resolve()\n",
    "    \n",
    "    if not byclass_path.exists():\n",
    "        raise FileNotFoundError(f\"Dataset directory '{byclass_dir}' not found.\")\n",
    "    \n",
    "    # Use glob for faster directory scanning\n",
    "    image_patterns = [f\"**/*{ext}\" for ext in VALID_EXTENSIONS]\n",
    "    \n",
    "    for pattern in image_patterns:\n",
    "        for filepath in byclass_path.glob(pattern):\n",
    "            if filepath.is_file():\n",
    "                class_name = filepath.parent.name\n",
    "                filepaths.append(str(filepath))\n",
    "                str_labels.append(class_name)\n",
    "    \n",
    "    if len(filepaths) == 0:\n",
    "        return [], [], {}, {}\n",
    "    \n",
    "    label_names = sorted(set(str_labels))\n",
    "    label2idx = {lab: i for i, lab in enumerate(label_names)}\n",
    "    idx2label = {i: lab for lab, i in label2idx.items()}\n",
    "    int_labels = [label2idx[s] for s in str_labels]\n",
    "    \n",
    "    print(f\"Scanned {len(filepaths)} valid images across {len(label2idx)} classes\")\n",
    "    return filepaths, int_labels, label2idx, idx2label\n",
    "\n",
    "# =========================\n",
    "# Preprocessing & Augmentation\n",
    "# =========================\n",
    "def load_and_preprocess_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img, channels=1, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    if INVERT:\n",
    "        img = 1.0 - img\n",
    "    return img, label\n",
    "\n",
    "def get_simple_augmentation() -> keras.Sequential:\n",
    "    return keras.Sequential([\n",
    "        keras.layers.RandomRotation(0.05, fill_mode=\"constant\", seed=RANDOM_SEED),\n",
    "        keras.layers.RandomZoom(0.05, fill_mode=\"constant\", seed=RANDOM_SEED+1),\n",
    "        keras.layers.RandomContrast(0.1, seed=RANDOM_SEED+2),\n",
    "    ], name=\"simple_data_augmentation\")\n",
    "\n",
    "AUGMENTOR = get_simple_augmentation()\n",
    "\n",
    "def build_optimized_dataset(paths: List[str], labels: np.ndarray, training: bool, batch_size: int) -> tf.data.Dataset:\n",
    "    \"\"\"Optimized dataset building without caching\"\"\"\n",
    "    ds = tf.data.Dataset.from_tensor_slices((tf.constant(paths), tf.constant(labels, dtype=tf.int32)))\n",
    "    \n",
    "    if training:\n",
    "        ds = ds.shuffle(min(SHUFFLE_BUFFER, len(paths)), seed=RANDOM_SEED, reshuffle_each_iteration=True)\n",
    "    \n",
    "    ds = ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.map(lambda img, label: (tf.ensure_shape(img, IMG_SIZE + (1,)), label),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if training:\n",
    "        ds = ds.repeat()\n",
    "        \n",
    "        def _apply_aug(img, label):\n",
    "            img_exp = tf.expand_dims(img, 0)\n",
    "            img_aug = AUGMENTOR(img_exp, training=True)\n",
    "            img_aug = tf.squeeze(img_aug, 0)\n",
    "            return img_aug, label\n",
    "        \n",
    "        ds = ds.map(_apply_aug, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# =========================\n",
    "# Model Loading\n",
    "# =========================\n",
    "def load_pretrained_model(model_path, num_classes):\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Pretrained model not found: {model_path}\")\n",
    "    \n",
    "    print(f\"📥 Loading pretrained model from: {model_path}\")\n",
    "    model = keras.models.load_model(model_path)\n",
    "    \n",
    "    # Check if the model output matches our number of classes\n",
    "    output_shape = model.output_shape\n",
    "    if output_shape and len(output_shape) > 1 and output_shape[-1] != num_classes:\n",
    "        print(f\"⚠️  Model output shape {output_shape[-1]} doesn't match number of classes {num_classes}\")\n",
    "        print(\"🔄 Replacing the final classification layer...\")\n",
    "        \n",
    "        # Remove the last layer\n",
    "        model = keras.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "        \n",
    "        # Add new classification layer\n",
    "        x = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"new_classification\")(model.output)\n",
    "        model = keras.Model(inputs=model.input, outputs=x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# Training Utils\n",
    "# =========================\n",
    "def get_optimizer():\n",
    "    # Increased learning rate for faster convergence\n",
    "    return keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "def get_advanced_callbacks():\n",
    "    return [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            BEST_MODEL_PATH, \n",
    "            monitor=\"val_accuracy\", \n",
    "            save_best_only=True, \n",
    "            mode=\"max\",\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_accuracy\", \n",
    "            patience=3,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.002,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", \n",
    "            factor=0.5, \n",
    "            patience=2,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "def compute_class_weights(y_train):\n",
    "    class_counts = np.bincount(y_train)\n",
    "    total_samples = len(y_train)\n",
    "    num_classes = len(class_counts)\n",
    "    \n",
    "    # Handle zero counts\n",
    "    class_counts = np.where(class_counts == 0, 1, class_counts)\n",
    "    \n",
    "    class_weights = total_samples / (num_classes * class_counts.astype(float))\n",
    "    class_weights = class_weights / np.mean(class_weights)\n",
    "    \n",
    "    return {i: float(weight) for i, weight in enumerate(class_weights)}\n",
    "\n",
    "# =========================\n",
    "# Stratified Split\n",
    "# =========================\n",
    "def stratified_split(filepaths, labels, test_size=0.15, random_state=42):\n",
    "    \"\"\"Simple stratified split implementation without scikit-learn\"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    # Group by class\n",
    "    class_groups = defaultdict(list)\n",
    "    for path, label in zip(filepaths, labels):\n",
    "        class_groups[label].append(path)\n",
    "    \n",
    "    train_paths, val_paths = [], []\n",
    "    train_labels, val_labels = [], []\n",
    "    \n",
    "    for label, paths in class_groups.items():\n",
    "        n_val = max(1, int(len(paths) * test_size))\n",
    "        random.shuffle(paths)\n",
    "        \n",
    "        val_paths.extend(paths[:n_val])\n",
    "        train_paths.extend(paths[n_val:])\n",
    "        \n",
    "        val_labels.extend([label] * n_val)\n",
    "        train_labels.extend([label] * (len(paths) - n_val))\n",
    "    \n",
    "    # Shuffle the datasets\n",
    "    train_data = list(zip(train_paths, train_labels))\n",
    "    val_data = list(zip(val_paths, val_labels))\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(val_data)\n",
    "    \n",
    "    train_paths, train_labels = zip(*train_data) if train_data else ([], [])\n",
    "    val_paths, val_labels = zip(*val_data) if val_data else ([], [])\n",
    "    \n",
    "    return list(train_paths), list(val_paths), np.array(train_labels), np.array(val_labels)\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    set_all_seeds(RANDOM_SEED)\n",
    "    setup_gpu_memory()\n",
    "    \n",
    "    # Disable mixed precision for now to avoid issues\n",
    "    try:\n",
    "        from tensorflow.keras import mixed_precision\n",
    "        mixed_precision.set_global_policy('float32')\n",
    "        print(\"✅ Using float32 precision for stability\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(\"🔍 Checking dataset availability...\")\n",
    "    if not ensure_dataset_available():\n",
    "        print(\"❌ Dataset preparation failed. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"🔍 Scanning byclass dataset...\")\n",
    "    filepaths, labels, label2idx, idx2label = scan_dataset_byclass(DATASET_DIR)\n",
    "    \n",
    "    if len(filepaths) == 0:\n",
    "        print(\"❌ No images found after extraction. Please check your archive file.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(filepaths)} images across {len(label2idx)} classes\")\n",
    "\n",
    "    # Use our custom stratified split\n",
    "    train_paths, val_paths, y_train, y_val = stratified_split(filepaths, labels, test_size=VAL_SPLIT, random_state=RANDOM_SEED)\n",
    "\n",
    "    steps_per_epoch = max(1, len(train_paths) // BATCH_SIZE)\n",
    "    validation_steps = max(1, len(val_paths) // BATCH_SIZE)\n",
    "\n",
    "    class_weights = compute_class_weights(y_train)\n",
    "\n",
    "    print(\"📥 Loading or creating model...\")\n",
    "    try:\n",
    "        model = load_pretrained_model(PRETRAINED_MODEL, len(label2idx))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load pretrained model: {e}\")\n",
    "        print(\"🔄 Creating a new model...\")\n",
    "        # Create a simpler model if loading fails\n",
    "        inputs = keras.layers.Input(shape=IMG_SIZE + (1,))\n",
    "        x = keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "        x = keras.layers.MaxPooling2D(2)(x)\n",
    "        x = keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = keras.layers.MaxPooling2D(2)(x)\n",
    "        x = keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = keras.layers.Dropout(0.5)(x)\n",
    "        outputs = keras.layers.Dense(len(label2idx), activation=\"softmax\")(x)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(optimizer=get_optimizer(), \n",
    "                 loss=\"sparse_categorical_crossentropy\", \n",
    "                 metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    print(f\"\\n📊 Training samples: {len(train_paths)}\")\n",
    "    print(f\"📊 Validation samples: {len(val_paths)}\")\n",
    "    print(f\"📊 Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"📊 Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"📊 Learning rate: 0.001\")\n",
    "\n",
    "    print(\"\\n🚀 Starting training...\")\n",
    "    \n",
    "    # Build datasets\n",
    "    ds_train = build_optimized_dataset(train_paths, y_train, training=True, batch_size=BATCH_SIZE)\n",
    "    ds_val = build_optimized_dataset(val_paths, y_val, training=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Test one batch to ensure it works\n",
    "    print(\"Testing data pipeline...\")\n",
    "    for batch in ds_train.take(1):\n",
    "        print(f\"Batch shape: {batch[0].shape}, Labels shape: {batch[1].shape}\")\n",
    "        break\n",
    "\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=ds_val,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=get_advanced_callbacks(),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅ Training completed! Best model saved to: {BEST_MODEL_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb19a3d6-b1c3-422d-98d4-e7d40681fa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ GPU setup error: Physical devices cannot be modified after being initialized\n",
      "✅ Using float32 precision for stability\n",
      "🔍 Checking dataset availability...\n",
      "✅ Dataset already exists at: /home/rand-jadav/by_class/by_class\n",
      "🔍 Scanning byclass dataset...\n",
      "Scanned 1342017 valid images across 64 classes\n",
      "Found 1342017 images across 64 classes\n",
      "\n",
      "================================================================================\n",
      "DETAILED CLASS MAPPING WITH CHARACTERS\n",
      "================================================================================\n",
      "Index  Folder Name     Character  Sample Count\n",
      "--------------------------------------------------------------------------------\n",
      "0      hsf_0           0          157747      \n",
      "1      hsf_1           1          141750      \n",
      "2      hsf_2           2          122646      \n",
      "3      hsf_3           3          74195       \n",
      "4      hsf_4           4          68783       \n",
      "5      hsf_6           5          77614       \n",
      "6      hsf_7           6          72748       \n",
      "7      train_30        7          34803       \n",
      "8      train_32        8          34184       \n",
      "9      train_34        9          33432       \n",
      "10     train_35        A          31067       \n",
      "11     train_36        B          34079       \n",
      "12     train_37        C          35796       \n",
      "13     train_38        D          33884       \n",
      "14     train_39        E          33720       \n",
      "15     train_41        F          7010        \n",
      "16     train_42        G          4091        \n",
      "17     train_43        H          11315       \n",
      "18     train_44        I          4945        \n",
      "19     train_45        J          5420        \n",
      "20     train_46        K          10203       \n",
      "21     train_48        L          3271        \n",
      "22     train_49        M          13179       \n",
      "23     train_4a        N          3962        \n",
      "24     train_4b        O          2473        \n",
      "25     train_4d        P          10027       \n",
      "26     train_4e        Q          9149        \n",
      "27     train_4f        R          28680       \n",
      "28     train_50        S          9277        \n",
      "29     train_51        T          2566        \n",
      "30     train_52        U          5436        \n",
      "31     train_54        V          10927       \n",
      "32     train_55        W          14146       \n",
      "33     train_56        X          4951        \n",
      "34     train_57        Y          5026        \n",
      "35     train_58        Z          2731        \n",
      "36     train_59        a          5088        \n",
      "37     train_5a        b          2698        \n",
      "38     train_61        c          11196       \n",
      "39     train_62        d          5551        \n",
      "40     train_63        e          2792        \n",
      "41     train_64        f          11421       \n",
      "42     train_65        g          28299       \n",
      "43     train_66        h          2493        \n",
      "44     train_67        i          3839        \n",
      "45     train_68        j          9713        \n",
      "46     train_69        k          2788        \n",
      "47     train_6a        l          1920        \n",
      "48     train_6b        m          2562        \n",
      "49     train_6c        n          16937       \n",
      "50     train_6d        o          2634        \n",
      "51     train_6e        p          12856       \n",
      "52     train_6f        q          2761        \n",
      "53     train_70        r          2401        \n",
      "54     train_71        s          3115        \n",
      "55     train_72        t          15934       \n",
      "56     train_73        u          2698        \n",
      "57     train_74        v          20793       \n",
      "58     train_75        w          2837        \n",
      "59     train_76        x          2854        \n",
      "60     train_77        y          2699        \n",
      "61     train_78        z          2820        \n",
      "62     train_79        Unknown    2359        \n",
      "63     train_7a        Unknown    2726        \n",
      "================================================================================\n",
      "📥 Loading or creating model...\n",
      "📥 Loading pretrained model from: best_model_byclass_finetuned.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ new_classification (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ image (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ new_classification (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,743,552</span> (10.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,743,552\u001b[0m (10.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,739,200</span> (10.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,739,200\u001b[0m (10.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> (17.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,352\u001b[0m (17.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training samples: 1140745\n",
      "📊 Validation samples: 201272\n",
      "📊 Steps per epoch: 35648\n",
      "📊 Batch size: 32\n",
      "📊 Learning rate: 0.001\n",
      "\n",
      "🚀 Starting training...\n",
      "Testing data pipeline...\n",
      "Batch shape: (32, 128, 128, 1), Labels shape: (32,)\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 12:11:58.299757: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_9}}\n",
      "E0000 00:00:1758177721.509386  114479 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_13_1/dropout_7_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  121/35648\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34:07\u001b[0m 260ms/step - accuracy: 0.4051 - loss: 0.2613"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 575\u001b[39m\n\u001b[32m    572\u001b[39m         traceback.print_exc()\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 553\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch[\u001b[32m0\u001b[39m].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Labels shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch[\u001b[32m1\u001b[39m].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_advanced_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    562\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Analyze validation accuracy\u001b[39;00m\n\u001b[32m    565\u001b[39m analyze_validation_accuracy(history, model, val_paths, y_val, idx2label)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf-gpu-env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf-gpu-env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf-gpu-env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:221\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m     iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m ):\n\u001b[32m    220\u001b[39m     opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs.get_value()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf-gpu-env/lib/python3.12/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[39m, in \u001b[36m_OptionalImpl.has_value\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28mself\u001b[39m._variant_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf-gpu-env/lib/python3.12/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[39m, in \u001b[36moptional_has_value\u001b[39m\u001b[34m(optional, name)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m    171\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOptionalHasValue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# emnist_byclass_finetune_optimized_4050.py\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import zipfile\n",
    "import tarfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# -----------------------\n",
    "# User config - OPTIMIZED for RTX 4050\n",
    "# -----------------------\n",
    "DATASET_DIR = \"/home/rand-jadav/by_class/by_class\"\n",
    "DATASET_ARCHIVE = \"/home/rand-jadav/Downloads/by.zip\"\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "VAL_SPLIT = 0.15\n",
    "RANDOM_SEED = 42\n",
    "SHUFFLE_BUFFER = 10000\n",
    "INVERT = True\n",
    "PRETRAINED_MODEL = \"best_model_byclass_finetuned.keras\"\n",
    "BEST_MODEL_PATH = \"best_model_byclass__2.keras\"\n",
    "LABELMAP_JSON = \"byclass_labelmap.json\"\n",
    "\n",
    "VALID_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\", \".webp\", \".tiff\", \".tif\"}\n",
    "SUPPORTED_ARCHIVES = {\".zip\", \".tar\", \".gz\", \".bz2\", \".tar.gz\", \".tar.bz2\"}\n",
    "\n",
    "# =========================\n",
    "# Archive Extraction Functions\n",
    "# =========================\n",
    "def extract_archive(archive_path: str, extract_to: str) -> bool:\n",
    "    \"\"\"Extract supported archive formats automatically\"\"\"\n",
    "    archive_path = Path(archive_path)\n",
    "    extract_to = Path(extract_to)\n",
    "    \n",
    "    if not archive_path.exists():\n",
    "        print(f\"❌ Archive not found: {archive_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Create extraction directory if it doesn't exist\n",
    "    extract_to.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        if archive_path.suffix == \".zip\":\n",
    "            print(f\"📦 Extracting ZIP archive: {archive_path}\")\n",
    "            with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_to)\n",
    "            print(\"✅ ZIP extraction completed\")\n",
    "            \n",
    "        elif archive_path.suffix in [\".tar\", \".gz\", \".bz2\", \".tar.gz\", \".tar.bz2\"]:\n",
    "            print(f\"📦 Extracting TAR archive: {archive_path}\")\n",
    "            if archive_path.suffix in [\".gz\", \".tar.gz\"]:\n",
    "                mode = \"r:gz\"\n",
    "            elif archive_path.suffix in [\".bz2\", \".tar.bz2\"]:\n",
    "                mode = \"r:bz2\"\n",
    "            else:\n",
    "                mode = \"r\"\n",
    "            \n",
    "            with tarfile.open(archive_path, mode) as tar_ref:\n",
    "                tar_ref.extractall(extract_to)\n",
    "            print(\"✅ TAR extraction completed\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"❌ Unsupported archive format: {archive_path.suffix}\")\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Extraction failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def ensure_dataset_available():\n",
    "    \"\"\"Check if dataset exists, extract if needed\"\"\"\n",
    "    dataset_path = Path(DATASET_DIR)\n",
    "    archive_path = Path(DATASET_ARCHIVE)\n",
    "    \n",
    "    # Check if dataset already exists\n",
    "    if dataset_path.exists() and any(dataset_path.iterdir()):\n",
    "        print(f\"✅ Dataset already exists at: {DATASET_DIR}\")\n",
    "        return True\n",
    "    \n",
    "    # Check if archive exists and extract\n",
    "    if archive_path.exists():\n",
    "        print(f\"📦 Found archive: {archive_path}\")\n",
    "        print(\"🔄 Extracting dataset...\")\n",
    "        if extract_archive(archive_path, dataset_path):\n",
    "            # Verify extraction\n",
    "            if dataset_path.exists() and any(dataset_path.iterdir()):\n",
    "                print(\"✅ Dataset extraction verified\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"❌ Extraction completed but no files found\")\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"❌ Neither dataset nor archive found:\")\n",
    "        print(f\"   Dataset directory: {DATASET_DIR}\")\n",
    "        print(f\"   Archive file: {DATASET_ARCHIVE}\")\n",
    "        return False\n",
    "\n",
    "# =========================\n",
    "# GPU Memory Optimization\n",
    "# =========================\n",
    "def setup_gpu_memory():\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if not gpus:\n",
    "            print(\"ℹ️ No GPU detected, using CPU\")\n",
    "            return\n",
    "        \n",
    "        # Set memory growth first\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        # Then set memory limit if needed\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.set_logical_device_configuration(\n",
    "                    gpu,\n",
    "                    [tf.config.LogicalDeviceConfiguration(memory_limit=5120)]\n",
    "                )\n",
    "        except:\n",
    "            print(\"⚠️  Could not set memory limit, using memory growth only\")\n",
    "        \n",
    "        print(f\"✅ GPU configured: {len(gpus)} Physical GPU, {len(tf.config.list_logical_devices('GPU'))} Logical GPU\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ GPU setup error: {e}\")\n",
    "\n",
    "# =========================\n",
    "# Reproducibility\n",
    "# =========================\n",
    "def set_all_seeds(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "# =========================\n",
    "# Dataset scanning with detailed class printing\n",
    "# =========================\n",
    "def scan_dataset_byclass(byclass_dir: str) -> Tuple[List[str], List[int], Dict[str, int], Dict[int, str]]:\n",
    "    filepaths = []\n",
    "    str_labels = []\n",
    "    byclass_path = Path(byclass_dir).resolve()\n",
    "    \n",
    "    if not byclass_path.exists():\n",
    "        raise FileNotFoundError(f\"Dataset directory '{byclass_dir}' not found.\")\n",
    "    \n",
    "    # Use glob for faster directory scanning\n",
    "    image_patterns = [f\"**/*{ext}\" for ext in VALID_EXTENSIONS]\n",
    "    \n",
    "    for pattern in image_patterns:\n",
    "        for filepath in byclass_path.glob(pattern):\n",
    "            if filepath.is_file():\n",
    "                # Get class name from parent directory\n",
    "                class_name = filepath.parent.name\n",
    "                filepaths.append(str(filepath))\n",
    "                str_labels.append(class_name)\n",
    "    \n",
    "    if len(filepaths) == 0:\n",
    "        return [], [], {}, {}\n",
    "    \n",
    "    label_names = sorted(set(str_labels))\n",
    "    label2idx = {lab: i for i, lab in enumerate(label_names)}\n",
    "    idx2label = {i: lab for lab, i in label2idx.items()}\n",
    "    int_labels = [label2idx[s] for s in str_labels]\n",
    "    \n",
    "    print(f\"Scanned {len(filepaths)} valid images across {len(label2idx)} classes\")\n",
    "    return filepaths, int_labels, label2idx, idx2label, str_labels  # Return str_labels as well\n",
    "\n",
    "# =========================\n",
    "# Print all classes with character mapping\n",
    "# =========================\n",
    "def print_all_classes_with_characters(label2idx, idx2label, str_labels):\n",
    "    \"\"\"Print all classes with their corresponding characters\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED CLASS MAPPING WITH CHARACTERS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create a mapping from folder names to expected characters\n",
    "    # This is based on EMNIST byclass structure\n",
    "    folder_to_char = {\n",
    "        'hsf_0': '0', 'hsf_1': '1', 'hsf_2': '2', 'hsf_3': '3', 'hsf_4': '4',\n",
    "        'hsf_6': '5', 'hsf_7': '6', 'train_30': '7', 'train_32': '8', 'train_34': '9',\n",
    "        'train_35': 'A', 'train_36': 'B', 'train_37': 'C', 'train_38': 'D', 'train_39': 'E',\n",
    "        'train_41': 'F', 'train_42': 'G', 'train_43': 'H', 'train_44': 'I', 'train_45': 'J',\n",
    "        'train_46': 'K', 'train_48': 'L', 'train_49': 'M', 'train_4a': 'N', 'train_4b': 'O',\n",
    "        'train_4d': 'P', 'train_4e': 'Q', 'train_4f': 'R', 'train_50': 'S', 'train_51': 'T',\n",
    "        'train_52': 'U', 'train_54': 'V', 'train_55': 'W', 'train_56': 'X', 'train_57': 'Y',\n",
    "        'train_58': 'Z', 'train_59': 'a', 'train_5a': 'b', 'train_61': 'c', 'train_62': 'd',\n",
    "        'train_63': 'e', 'train_64': 'f', 'train_65': 'g', 'train_66': 'h', 'train_67': 'i',\n",
    "        'train_68': 'j', 'train_69': 'k', 'train_6a': 'l', 'train_6b': 'm', 'train_6c': 'n',\n",
    "        'train_6d': 'o', 'train_6e': 'p', 'train_6f': 'q', 'train_70': 'r', 'train_71': 's',\n",
    "        'train_72': 't', 'train_73': 'u', 'train_74': 'v', 'train_75': 'w', 'train_76': 'x',\n",
    "        'train_77': 'y', 'train_78': 'z'\n",
    "    }\n",
    "    \n",
    "    # Count samples per class\n",
    "    class_counts = Counter(str_labels)\n",
    "    \n",
    "    print(f\"{'Index':<6} {'Folder Name':<15} {'Character':<10} {'Sample Count':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for folder_name, class_idx in sorted(label2idx.items(), key=lambda x: x[1]):\n",
    "        character = folder_to_char.get(folder_name, 'Unknown')\n",
    "        count = class_counts.get(folder_name, 0)\n",
    "        print(f\"{class_idx:<6} {folder_name:<15} {character:<10} {count:<12}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "\n",
    "# =========================\n",
    "# Validation Accuracy Analysis Function\n",
    "# =========================\n",
    "def analyze_validation_accuracy(history, model, val_paths, y_val, idx2label):\n",
    "    \"\"\"Analyze and print validation accuracy details\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VALIDATION ACCURACY ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if history and hasattr(history, 'history'):\n",
    "        # Print final validation accuracy\n",
    "        if 'val_accuracy' in history.history and len(history.history['val_accuracy']) > 0:\n",
    "            final_val_acc = history.history['val_accuracy'][-1]\n",
    "            print(f\"Final Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
    "        \n",
    "        # Print training accuracy for comparison\n",
    "        if 'accuracy' in history.history and len(history.history['accuracy']) > 0:\n",
    "            final_train_acc = history.history['accuracy'][-1]\n",
    "            print(f\"Final Training Accuracy: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
    "        \n",
    "        # Print accuracy progression\n",
    "        if 'val_accuracy' in history.history:\n",
    "            print(\"\\nValidation Accuracy Progression:\")\n",
    "            for epoch, acc in enumerate(history.history['val_accuracy'], 1):\n",
    "                print(f\"  Epoch {epoch}: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    \n",
    "    # Calculate per-class accuracy if we have a model and validation data\n",
    "    if model is not None and val_paths is not None and y_val is not None and len(val_paths) > 0:\n",
    "        print(\"\\nCalculating per-class validation accuracy...\")\n",
    "        \n",
    "        try:\n",
    "            # Create a small validation dataset for evaluation\n",
    "            val_ds = tf.data.Dataset.from_tensor_slices((tf.constant(val_paths), tf.constant(y_val, dtype=tf.int32)))\n",
    "            val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "            \n",
    "            # Get predictions\n",
    "            predictions = model.predict(val_ds, verbose=1)\n",
    "            predicted_classes = np.argmax(predictions, axis=1)\n",
    "            \n",
    "            # Calculate per-class accuracy\n",
    "            class_correct = defaultdict(int)\n",
    "            class_total = defaultdict(int)\n",
    "            \n",
    "            for true_label, pred_label in zip(y_val, predicted_classes):\n",
    "                class_total[true_label] += 1\n",
    "                if true_label == pred_label:\n",
    "                    class_correct[true_label] += 1\n",
    "            \n",
    "            print(f\"\\nPer-class Validation Accuracy:\")\n",
    "            print(f\"{'Class':<6} {'Character':<10} {'Accuracy':<10} {'Correct/Total':<15}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            char_mapping = {\n",
    "                'hsf_0': '0', 'hsf_1': '1', 'hsf_2': '2', 'hsf_3': '3', 'hsf_4': '4',\n",
    "                'hsf_6': '5', 'hsf_7': '6', 'train_30': '7', 'train_32': '8', 'train_34': '9',\n",
    "                'train_35': 'A', 'train_36': 'B', 'train_37': 'C', 'train_38': 'D', 'train_39': 'E',\n",
    "                'train_41': 'F', 'train_42': 'G', 'train_43': 'H', 'train_44': 'I', 'train_45': 'J',\n",
    "                'train_46': 'K', 'train_48': 'L', 'train_49': 'M', 'train_4a': 'N', 'train_4b': 'O',\n",
    "                'train_4d': 'P', 'train_4e': 'Q', 'train_4f': 'R', 'train_50': 'S', 'train_51': 'T',\n",
    "                'train_52': 'U', 'train_54': 'V', 'train_55': 'W', 'train_56': 'X', 'train_57': 'Y',\n",
    "                'train_58': 'Z', 'train_59': 'a', 'train_5a': 'b', 'train_61': 'c', 'train_62': 'd',\n",
    "                'train_63': 'e', 'train_64': 'f', 'train_65': 'g', 'train_66': 'h', 'train_67': 'i',\n",
    "                'train_68': 'j', 'train_69': 'k', 'train_6a': 'l', 'train_6b': 'm', 'train_6c': 'n',\n",
    "                'train_6d': 'o', 'train_6e': 'p', 'train_6f': 'q', 'train_70': 'r', 'train_71': 's',\n",
    "                'train_72': 't', 'train_73': 'u', 'train_74': 'v', 'train_75': 'w', 'train_76': 'x',\n",
    "                'train_77': 'y', 'train_78': 'z'\n",
    "            }\n",
    "            \n",
    "            for class_idx in sorted(class_total.keys()):\n",
    "                accuracy = class_correct.get(class_idx, 0) / class_total[class_idx] if class_total[class_idx] > 0 else 0\n",
    "                folder_name = idx2label.get(class_idx, \"Unknown\")\n",
    "                character = char_mapping.get(folder_name, '?')\n",
    "                print(f\"{class_idx:<6} {character:<10} {accuracy:.3f}       {class_correct.get(class_idx, 0):<3}/{class_total[class_idx]:<3}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error during per-class accuracy calculation: {e}\")\n",
    "    else:\n",
    "        print(\"⚠️  Skipping per-class accuracy analysis - missing data or model\")\n",
    "\n",
    "# =========================\n",
    "# Preprocessing & Augmentation\n",
    "# =========================\n",
    "def load_and_preprocess_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img, channels=1, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    if INVERT:\n",
    "        img = 1.0 - img\n",
    "    return img, label\n",
    "\n",
    "def get_simple_augmentation() -> keras.Sequential:\n",
    "    return keras.Sequential([\n",
    "        keras.layers.RandomRotation(0.05, fill_mode=\"constant\", seed=RANDOM_SEED),\n",
    "        keras.layers.RandomZoom(0.05, fill_mode=\"constant\", seed=RANDOM_SEED+1),\n",
    "        keras.layers.RandomContrast(0.1, seed=RANDOM_SEED+2),\n",
    "    ], name=\"simple_data_augmentation\")\n",
    "\n",
    "AUGMENTOR = get_simple_augmentation()\n",
    "\n",
    "def build_optimized_dataset(paths: List[str], labels: np.ndarray, training: bool, batch_size: int) -> tf.data.Dataset:\n",
    "    \"\"\"Optimized dataset building without caching\"\"\"\n",
    "    if len(paths) == 0:\n",
    "        raise ValueError(\"No paths provided for dataset building\")\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((tf.constant(paths), tf.constant(labels, dtype=tf.int32)))\n",
    "    \n",
    "    if training:\n",
    "        ds = ds.shuffle(min(SHUFFLE_BUFFER, len(paths)), seed=RANDOM_SEED, reshuffle_each_iteration=True)\n",
    "    \n",
    "    ds = ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.map(lambda img, label: (tf.ensure_shape(img, IMG_SIZE + (1,)), label),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if training:\n",
    "        ds = ds.repeat()\n",
    "        \n",
    "        def _apply_aug(img, label):\n",
    "            img_exp = tf.expand_dims(img, 0)\n",
    "            img_aug = AUGMENTOR(img_exp, training=True)\n",
    "            img_aug = tf.squeeze(img_aug, 0)\n",
    "            return img_aug, label\n",
    "        \n",
    "        ds = ds.map(_apply_aug, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# =========================\n",
    "# Model Loading\n",
    "# =========================\n",
    "def load_pretrained_model(model_path, num_classes):\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Pretrained model not found: {model_path}\")\n",
    "    \n",
    "    print(f\"📥 Loading pretrained model from: {model_path}\")\n",
    "    model = keras.models.load_model(model_path)\n",
    "    \n",
    "    # Check if the model output matches our number of classes\n",
    "    output_shape = model.output_shape\n",
    "    if output_shape and len(output_shape) > 1 and output_shape[-1] != num_classes:\n",
    "        print(f\"⚠️  Model output shape {output_shape[-1]} doesn't match number of classes {num_classes}\")\n",
    "        print(\"🔄 Replacing the final classification layer...\")\n",
    "        \n",
    "        # Remove the last layer\n",
    "        model = keras.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "        \n",
    "        # Add new classification layer\n",
    "        x = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"new_classification\")(model.output)\n",
    "        model = keras.Model(inputs=model.input, outputs=x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# Training Utils\n",
    "# =========================\n",
    "def get_optimizer():\n",
    "    # Increased learning rate for faster convergence\n",
    "    return keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "def get_advanced_callbacks():\n",
    "    return [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            BEST_MODEL_PATH, \n",
    "            monitor=\"val_accuracy\", \n",
    "            save_best_only=True, \n",
    "            mode=\"max\",\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_accuracy\", \n",
    "            patience=3,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.002,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", \n",
    "            factor=0.5, \n",
    "            patience=2,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "def compute_class_weights(y_train):\n",
    "    if len(y_train) == 0:\n",
    "        return {}\n",
    "    \n",
    "    class_counts = np.bincount(y_train)\n",
    "    total_samples = len(y_train)\n",
    "    num_classes = len(class_counts)\n",
    "    \n",
    "    # Handle zero counts\n",
    "    class_counts = np.where(class_counts == 0, 1, class_counts)\n",
    "    \n",
    "    class_weights = total_samples / (num_classes * class_counts.astype(float))\n",
    "    class_weights = class_weights / np.mean(class_weights)\n",
    "    \n",
    "    return {i: float(weight) for i, weight in enumerate(class_weights)}\n",
    "\n",
    "# =========================\n",
    "# Stratified Split\n",
    "# =========================\n",
    "def stratified_split(filepaths, labels, test_size=0.15, random_state=42):\n",
    "    \"\"\"Simple stratified split implementation without scikit-learn\"\"\"\n",
    "    if len(filepaths) == 0:\n",
    "        return [], [], np.array([]), np.array([])\n",
    "    \n",
    "    # Group by class\n",
    "    class_groups = defaultdict(list)\n",
    "    for path, label in zip(filepaths, labels):\n",
    "        class_groups[label].append(path)\n",
    "    \n",
    "    train_paths, val_paths = [], []\n",
    "    train_labels, val_labels = [], []\n",
    "    \n",
    "    for label, paths in class_groups.items():\n",
    "        n_val = max(1, int(len(paths) * test_size))\n",
    "        random.shuffle(paths)\n",
    "        \n",
    "        val_paths.extend(paths[:n_val])\n",
    "        train_paths.extend(paths[n_val:])\n",
    "        \n",
    "        val_labels.extend([label] * n_val)\n",
    "        train_labels.extend([label] * (len(paths) - n_val))\n",
    "    \n",
    "    # Shuffle the datasets\n",
    "    train_data = list(zip(train_paths, train_labels))\n",
    "    val_data = list(zip(val_paths, val_labels))\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(val_data)\n",
    "    \n",
    "    train_paths, train_labels = zip(*train_data) if train_data else ([], [])\n",
    "    val_paths, val_labels = zip(*val_data) if val_data else ([], [])\n",
    "    \n",
    "    return list(train_paths), list(val_paths), np.array(train_labels), np.array(val_labels)\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    set_all_seeds(RANDOM_SEED)\n",
    "    setup_gpu_memory()\n",
    "    \n",
    "    # Disable mixed precision for now to avoid issues\n",
    "    try:\n",
    "        from tensorflow.keras import mixed_precision\n",
    "        mixed_precision.set_global_policy('float32')\n",
    "        print(\"✅ Using float32 precision for stability\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(\"🔍 Checking dataset availability...\")\n",
    "    if not ensure_dataset_available():\n",
    "        print(\"❌ Dataset preparation failed. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"🔍 Scanning byclass dataset...\")\n",
    "    filepaths, labels, label2idx, idx2label, str_labels = scan_dataset_byclass(DATASET_DIR)\n",
    "    \n",
    "    if len(filepaths) == 0:\n",
    "        print(\"❌ No images found after extraction. Please check your archive file.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(filepaths)} images across {len(label2idx)} classes\")\n",
    "\n",
    "    # Print all classes with characters\n",
    "    print_all_classes_with_characters(label2idx, idx2label, str_labels)\n",
    "\n",
    "    # Use our custom stratified split\n",
    "    train_paths, val_paths, y_train, y_val = stratified_split(filepaths, labels, test_size=VAL_SPLIT, random_state=RANDOM_SEED)\n",
    "\n",
    "    if len(train_paths) == 0:\n",
    "        print(\"❌ No training data available after split\")\n",
    "        return\n",
    "\n",
    "    steps_per_epoch = max(1, len(train_paths) // BATCH_SIZE)\n",
    "    validation_steps = max(1, len(val_paths) // BATCH_SIZE)\n",
    "\n",
    "    class_weights = compute_class_weights(y_train)\n",
    "\n",
    "    print(\"📥 Loading or creating model...\")\n",
    "    try:\n",
    "        model = load_pretrained_model(PRETRAINED_MODEL, len(label2idx))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load pretrained model: {e}\")\n",
    "        print(\"🔄 Creating a new model...\")\n",
    "        # Create a simpler model if loading fails\n",
    "        inputs = keras.layers.Input(shape=IMG_SIZE + (1,))\n",
    "        x = keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "        x = keras.layers.MaxPooling2D(2)(x)\n",
    "        x = keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = keras.layers.MaxPooling2D(2)(x)\n",
    "        x = keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = keras.layers.Dropout(0.5)(x)\n",
    "        outputs = keras.layers.Dense(len(label2idx), activation=\"softmax\")(x)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(optimizer=get_optimizer(), \n",
    "                 loss=\"sparse_categorical_crossentropy\", \n",
    "                 metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    print(f\"\\n📊 Training samples: {len(train_paths)}\")\n",
    "    print(f\"📊 Validation samples: {len(val_paths)}\")\n",
    "    print(f\"📊 Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"📊 Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"📊 Learning rate: 0.001\")\n",
    "\n",
    "    print(\"\\n🚀 Starting training...\")\n",
    "    \n",
    "    # Build datasets\n",
    "    try:\n",
    "        ds_train = build_optimized_dataset(train_paths, y_train, training=True, batch_size=BATCH_SIZE)\n",
    "        ds_val = build_optimized_dataset(val_paths, y_val, training=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "        # Test one batch to ensure it works\n",
    "        print(\"Testing data pipeline...\")\n",
    "        for batch in ds_train.take(1):\n",
    "            print(f\"Batch shape: {batch[0].shape}, Labels shape: {batch[1].shape}\")\n",
    "            break\n",
    "\n",
    "        history = model.fit(\n",
    "            ds_train,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=ds_val,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_steps=validation_steps,\n",
    "            class_weight=class_weights,\n",
    "            callbacks=get_advanced_callbacks(),\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Analyze validation accuracy\n",
    "        analyze_validation_accuracy(history, model, val_paths, y_val, idx2label)\n",
    "\n",
    "        print(f\"\\n✅ Training completed! Best model saved to: {BEST_MODEL_PATH}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Training failed with error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675277a6-0ef1-4495-ba6b-44e0454de2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ GPU setup error: Physical devices cannot be modified after being initialized\n",
      "✅ Using float32 precision for stability\n",
      "🔍 Checking dataset availability...\n",
      "✅ Dataset already exists at: /home/rand-jadav/by_class/by_class\n",
      "🔍 Scanning byclass dataset...\n",
      "Scanned 1342017 valid images across 64 classes\n",
      "Found 1342017 images across 64 classes\n",
      "\n",
      "================================================================================\n",
      "DETAILED CLASS MAPPING WITH AUTOMATIC CHARACTER DETECTION\n",
      "================================================================================\n",
      "Index  Folder Name          Character  Sample Count\n",
      "--------------------------------------------------------------------------------\n",
      "0      hsf_0                h          157747      \n",
      "1      hsf_1                h          141750      \n",
      "2      hsf_2                h          122646      \n",
      "3      hsf_3                h          74195       \n",
      "4      hsf_4                h          68783       \n",
      "5      hsf_6                h          77614       \n",
      "6      hsf_7                h          72748       \n",
      "7      train_30             0          34803       \n",
      "8      train_32             2          34184       \n",
      "9      train_34             4          33432       \n",
      "10     train_35             5          31067       \n",
      "11     train_36             6          34079       \n",
      "12     train_37             7          35796       \n",
      "13     train_38             8          33884       \n",
      "14     train_39             9          33720       \n",
      "15     train_41             A          7010        \n",
      "16     train_42             B          4091        \n",
      "17     train_43             C          11315       \n",
      "18     train_44             D          4945        \n",
      "19     train_45             E          5420        \n",
      "20     train_46             F          10203       \n",
      "21     train_48             H          3271        \n",
      "22     train_49             I          13179       \n",
      "23     train_4a             J          3962        \n",
      "24     train_4b             K          2473        \n",
      "25     train_4d             M          10027       \n",
      "26     train_4e             N          9149        \n",
      "27     train_4f             O          28680       \n",
      "28     train_50             P          9277        \n",
      "29     train_51             Q          2566        \n",
      "30     train_52             R          5436        \n",
      "31     train_54             T          10927       \n",
      "32     train_55             U          14146       \n",
      "33     train_56             V          4951        \n",
      "34     train_57             W          5026        \n",
      "35     train_58             X          2731        \n",
      "36     train_59             Y          5088        \n",
      "37     train_5a             Z          2698        \n",
      "38     train_61             a          11196       \n",
      "39     train_62             b          5551        \n",
      "40     train_63             c          2792        \n",
      "41     train_64             d          11421       \n",
      "42     train_65             e          28299       \n",
      "43     train_66             f          2493        \n",
      "44     train_67             g          3839        \n",
      "45     train_68             h          9713        \n",
      "46     train_69             i          2788        \n",
      "47     train_6a             j          1920        \n",
      "48     train_6b             k          2562        \n",
      "49     train_6c             l          16937       \n",
      "50     train_6d             m          2634        \n",
      "51     train_6e             n          12856       \n",
      "52     train_6f             o          2761        \n",
      "53     train_70             p          2401        \n",
      "54     train_71             q          3115        \n",
      "55     train_72             r          15934       \n",
      "56     train_73             s          2698        \n",
      "57     train_74             t          20793       \n",
      "58     train_75             u          2837        \n",
      "59     train_76             v          2854        \n",
      "60     train_77             w          2699        \n",
      "61     train_78             x          2820        \n",
      "62     train_79             y          2359        \n",
      "63     train_7a             z          2726        \n",
      "================================================================================\n",
      "📥 Loading or creating model...\n",
      "📥 Loading pretrained model from: best_model_byclass_finetuned.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ new_classification (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ image (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ new_classification (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,743,552</span> (10.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,743,552\u001b[0m (10.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,739,200</span> (10.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,739,200\u001b[0m (10.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> (17.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,352\u001b[0m (17.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training samples: 1140745\n",
      "📊 Validation samples: 201272\n",
      "📊 Steps per epoch: 71296\n",
      "📊 Batch size: 16\n",
      "📊 Learning rate: 0.001\n",
      "\n",
      "🚀 Starting training...\n",
      "Testing data pipeline...\n",
      "Batch shape: (16, 128, 128, 1), Labels shape: (16,)\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 12:26:09.782531: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_9}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   30/71296\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:25:26\u001b[0m 122ms/step - accuracy: 0.3956 - loss: 0.3001"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 598\u001b[39m\n\u001b[32m    595\u001b[39m         traceback.print_exc()\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 576\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    573\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch[\u001b[32m0\u001b[39m].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Labels shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch[\u001b[32m1\u001b[39m].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    574\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m    \u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_advanced_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    585\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[38;5;66;03m# Analyze validation accuracy with the detected character mapping\u001b[39;00m\n\u001b[32m    588\u001b[39m analyze_validation_accuracy(history, model, val_paths, y_val, idx2label, folder_to_char)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf-gpu-env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf-gpu-env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf-gpu-env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:221\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m     iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m ):\n\u001b[32m    220\u001b[39m     opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs.get_value()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf-gpu-env/lib/python3.12/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[39m, in \u001b[36m_OptionalImpl.has_value\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28mself\u001b[39m._variant_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf-gpu-env/lib/python3.12/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[39m, in \u001b[36moptional_has_value\u001b[39m\u001b[34m(optional, name)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m    171\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOptionalHasValue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# emnist_byclass_finetune_optimized_4050.py\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import zipfile\n",
    "import tarfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# -----------------------\n",
    "# User config - OPTIMIZED for RTX 4050\n",
    "# -----------------------\n",
    "DATASET_DIR = \"/home/rand-jadav/by_class/by_class\"\n",
    "DATASET_ARCHIVE = \"/home/rand-jadav/Downloads/by.zip\"\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 2\n",
    "VAL_SPLIT = 0.15\n",
    "RANDOM_SEED = 42\n",
    "SHUFFLE_BUFFER = 10000\n",
    "INVERT = True\n",
    "PRETRAINED_MODEL = \"best_model_byclass_finetuned.keras\"\n",
    "BEST_MODEL_PATH = \"best_model_byclass__2.keras\"\n",
    "LABELMAP_JSON = \"byclass_labelmap.json\"\n",
    "\n",
    "VALID_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\", \".webp\", \".tiff\", \".tif\"}\n",
    "SUPPORTED_ARCHIVES = {\".zip\", \".tar\", \".gz\", \".bz2\", \".tar.gz\", \".tar.bz2\"}\n",
    "\n",
    "# =========================\n",
    "# Archive Extraction Functions\n",
    "# =========================\n",
    "def extract_archive(archive_path: str, extract_to: str) -> bool:\n",
    "    \"\"\"Extract supported archive formats automatically\"\"\"\n",
    "    archive_path = Path(archive_path)\n",
    "    extract_to = Path(extract_to)\n",
    "    \n",
    "    if not archive_path.exists():\n",
    "        print(f\"❌ Archive not found: {archive_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Create extraction directory if it doesn't exist\n",
    "    extract_to.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        if archive_path.suffix == \".zip\":\n",
    "            print(f\"📦 Extracting ZIP archive: {archive_path}\")\n",
    "            with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_to)\n",
    "            print(\"✅ ZIP extraction completed\")\n",
    "            \n",
    "        elif archive_path.suffix in [\".tar\", \".gz\", \".bz2\", \".tar.gz\", \".tar.bz2\"]:\n",
    "            print(f\"📦 Extracting TAR archive: {archive_path}\")\n",
    "            if archive_path.suffix in [\".gz\", \".tar.gz\"]:\n",
    "                mode = \"r:gz\"\n",
    "            elif archive_path.suffix in [\".bz2\", \".tar.bz2\"]:\n",
    "                mode = \"r:bz2\"\n",
    "            else:\n",
    "                mode = \"r\"\n",
    "            \n",
    "            with tarfile.open(archive_path, mode) as tar_ref:\n",
    "                tar_ref.extractall(extract_to)\n",
    "            print(\"✅ TAR extraction completed\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"❌ Unsupported archive format: {archive_path.suffix}\")\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Extraction failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def ensure_dataset_available():\n",
    "    \"\"\"Check if dataset exists, extract if needed\"\"\"\n",
    "    dataset_path = Path(DATASET_DIR)\n",
    "    archive_path = Path(DATASET_ARCHIVE)\n",
    "    \n",
    "    # Check if dataset already exists\n",
    "    if dataset_path.exists() and any(dataset_path.iterdir()):\n",
    "        print(f\"✅ Dataset already exists at: {DATASET_DIR}\")\n",
    "        return True\n",
    "    \n",
    "    # Check if archive exists and extract\n",
    "    if archive_path.exists():\n",
    "        print(f\"📦 Found archive: {archive_path}\")\n",
    "        print(\"🔄 Extracting dataset...\")\n",
    "        if extract_archive(archive_path, dataset_path):\n",
    "            # Verify extraction\n",
    "            if dataset_path.exists() and any(dataset_path.iterdir()):\n",
    "                print(\"✅ Dataset extraction verified\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"❌ Extraction completed but no files found\")\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"❌ Neither dataset nor archive found:\")\n",
    "        print(f\"   Dataset directory: {DATASET_DIR}\")\n",
    "        print(f\"   Archive file: {DATASET_ARCHIVE}\")\n",
    "        return False\n",
    "\n",
    "# =========================\n",
    "# GPU Memory Optimization\n",
    "# =========================\n",
    "def setup_gpu_memory():\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if not gpus:\n",
    "            print(\"ℹ️ No GPU detected, using CPU\")\n",
    "            return\n",
    "        \n",
    "        # Set memory growth first\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        # Then set memory limit if needed\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.set_logical_device_configuration(\n",
    "                    gpu,\n",
    "                    [tf.config.LogicalDeviceConfiguration(memory_limit=5120)]\n",
    "                )\n",
    "        except:\n",
    "            print(\"⚠️  Could not set memory limit, using memory growth only\")\n",
    "        \n",
    "        print(f\"✅ GPU configured: {len(gpus)} Physical GPU, {len(tf.config.list_logical_devices('GPU'))} Logical GPU\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ GPU setup error: {e}\")\n",
    "\n",
    "# =========================\n",
    "# Reproducibility\n",
    "# =========================\n",
    "def set_all_seeds(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "# =========================\n",
    "# Dataset scanning with detailed class printing\n",
    "# =========================\n",
    "def scan_dataset_byclass(byclass_dir: str) -> Tuple[List[str], List[int], Dict[str, int], Dict[int, str]]:\n",
    "    filepaths = []\n",
    "    str_labels = []\n",
    "    byclass_path = Path(byclass_dir).resolve()\n",
    "    \n",
    "    if not byclass_path.exists():\n",
    "        raise FileNotFoundError(f\"Dataset directory '{byclass_dir}' not found.\")\n",
    "    \n",
    "    # Use glob for faster directory scanning\n",
    "    image_patterns = [f\"**/*{ext}\" for ext in VALID_EXTENSIONS]\n",
    "    \n",
    "    for pattern in image_patterns:\n",
    "        for filepath in byclass_path.glob(pattern):\n",
    "            if filepath.is_file():\n",
    "                # Get class name from parent directory\n",
    "                class_name = filepath.parent.name\n",
    "                filepaths.append(str(filepath))\n",
    "                str_labels.append(class_name)\n",
    "    \n",
    "    if len(filepaths) == 0:\n",
    "        return [], [], {}, {}\n",
    "    \n",
    "    label_names = sorted(set(str_labels))\n",
    "    label2idx = {lab: i for i, lab in enumerate(label_names)}\n",
    "    idx2label = {i: lab for lab, i in label2idx.items()}\n",
    "    int_labels = [label2idx[s] for s in str_labels]\n",
    "    \n",
    "    print(f\"Scanned {len(filepaths)} valid images across {len(label2idx)} classes\")\n",
    "    return filepaths, int_labels, label2idx, idx2label, str_labels  # Return str_labels as well\n",
    "\n",
    "# =========================\n",
    "# Character detection from folder names\n",
    "# =========================\n",
    "def detect_character_from_folder(folder_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Try to detect the character from folder name using various strategies\n",
    "    \"\"\"\n",
    "    # Common patterns in EMNIST byclass dataset\n",
    "    folder_lower = folder_name.lower()\n",
    "    \n",
    "    # Check if folder name contains hex codes (common in EMNIST)\n",
    "    if folder_name.startswith(('hsf_', 'train_', 'test_')):\n",
    "        # Try to extract hex part and convert to character\n",
    "        parts = folder_name.split('_')\n",
    "        if len(parts) > 1:\n",
    "            hex_part = parts[-1]\n",
    "            try:\n",
    "                # Try to interpret as hex code\n",
    "                char_code = int(hex_part, 16)\n",
    "                if 32 <= char_code <= 126:  # Printable ASCII range\n",
    "                    return chr(char_code)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    \n",
    "    # Check if folder name is already a single character\n",
    "    if len(folder_name) == 1 and folder_name.isprintable():\n",
    "        return folder_name\n",
    "    \n",
    "    # Check for common patterns\n",
    "    if 'digit' in folder_lower or 'number' in folder_lower:\n",
    "        # Look for digits in the name\n",
    "        for char in folder_name:\n",
    "            if char.isdigit():\n",
    "                return char\n",
    "    \n",
    "    if 'letter' in folder_lower or 'char' in folder_lower:\n",
    "        # Look for letters in the name\n",
    "        for char in folder_name:\n",
    "            if char.isalpha():\n",
    "                return char\n",
    "    \n",
    "    # Try to find any printable character in the name\n",
    "    for char in folder_name:\n",
    "        if char.isprintable() and not char.isspace() and char not in ['_', '-']:\n",
    "            return char\n",
    "    \n",
    "    # If all else fails, return the first character or question mark\n",
    "    return folder_name[0] if folder_name else '?'\n",
    "\n",
    "# =========================\n",
    "# Print all classes with automatically detected characters\n",
    "# =========================\n",
    "def print_all_classes_with_characters(label2idx, idx2label, str_labels):\n",
    "    \"\"\"Print all classes with their automatically detected characters\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED CLASS MAPPING WITH AUTOMATIC CHARACTER DETECTION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Count samples per class\n",
    "    class_counts = Counter(str_labels)\n",
    "    \n",
    "    # Detect characters for each folder\n",
    "    folder_to_char = {}\n",
    "    for folder_name in label2idx.keys():\n",
    "        folder_to_char[folder_name] = detect_character_from_folder(folder_name)\n",
    "    \n",
    "    print(f\"{'Index':<6} {'Folder Name':<20} {'Character':<10} {'Sample Count':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for folder_name, class_idx in sorted(label2idx.items(), key=lambda x: x[1]):\n",
    "        character = folder_to_char.get(folder_name, '?')\n",
    "        count = class_counts.get(folder_name, 0)\n",
    "        print(f\"{class_idx:<6} {folder_name:<20} {character:<10} {count:<12}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Return the character mapping for later use\n",
    "    return folder_to_char\n",
    "\n",
    "# =========================\n",
    "# Validation Accuracy Analysis Function\n",
    "# =========================\n",
    "def analyze_validation_accuracy(history, model, val_paths, y_val, idx2label, folder_to_char):\n",
    "    \"\"\"Analyze and print validation accuracy details\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VALIDATION ACCURACY ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if history and hasattr(history, 'history'):\n",
    "        # Print final validation accuracy\n",
    "        if 'val_accuracy' in history.history and len(history.history['val_accuracy']) > 0:\n",
    "            final_val_acc = history.history['val_accuracy'][-1]\n",
    "            print(f\"Final Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
    "        \n",
    "        # Print training accuracy for comparison\n",
    "        if 'accuracy' in history.history and len(history.history['accuracy']) > 0:\n",
    "            final_train_acc = history.history['accuracy'][-1]\n",
    "            print(f\"Final Training Accuracy: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
    "        \n",
    "        # Print accuracy progression\n",
    "        if 'val_accuracy' in history.history:\n",
    "            print(\"\\nValidation Accuracy Progression:\")\n",
    "            for epoch, acc in enumerate(history.history['val_accuracy'], 1):\n",
    "                print(f\"  Epoch {epoch}: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    \n",
    "    # Calculate per-class accuracy if we have a model and validation data\n",
    "    if model is not None and val_paths is not None and y_val is not None and len(val_paths) > 0:\n",
    "        print(\"\\nCalculating per-class validation accuracy...\")\n",
    "        \n",
    "        try:\n",
    "            # Create a small validation dataset for evaluation\n",
    "            val_ds = tf.data.Dataset.from_tensor_slices((tf.constant(val_paths), tf.constant(y_val, dtype=tf.int32)))\n",
    "            val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "            \n",
    "            # Get predictions\n",
    "            predictions = model.predict(val_ds, verbose=1)\n",
    "            predicted_classes = np.argmax(predictions, axis=1)\n",
    "            \n",
    "            # Calculate per-class accuracy\n",
    "            class_correct = defaultdict(int)\n",
    "            class_total = defaultdict(int)\n",
    "            \n",
    "            for true_label, pred_label in zip(y_val, predicted_classes):\n",
    "                class_total[true_label] += 1\n",
    "                if true_label == pred_label:\n",
    "                    class_correct[true_label] += 1\n",
    "            \n",
    "            print(f\"\\nPer-class Validation Accuracy:\")\n",
    "            print(f\"{'Class':<6} {'Character':<10} {'Accuracy':<10} {'Correct/Total':<15}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            for class_idx in sorted(class_total.keys()):\n",
    "                accuracy = class_correct.get(class_idx, 0) / class_total[class_idx] if class_total[class_idx] > 0 else 0\n",
    "                folder_name = idx2label.get(class_idx, \"Unknown\")\n",
    "                character = folder_to_char.get(folder_name, '?')\n",
    "                print(f\"{class_idx:<6} {character:<10} {accuracy:.3f}       {class_correct.get(class_idx, 0):<3}/{class_total[class_idx]:<3}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error during per-class accuracy calculation: {e}\")\n",
    "    else:\n",
    "        print(\"⚠️  Skipping per-class accuracy analysis - missing data or model\")\n",
    "\n",
    "# =========================\n",
    "# Preprocessing & Augmentation\n",
    "# =========================\n",
    "def load_and_preprocess_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img, channels=1, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    if INVERT:\n",
    "        img = 1.0 - img\n",
    "    return img, label\n",
    "\n",
    "def get_simple_augmentation() -> keras.Sequential:\n",
    "    return keras.Sequential([\n",
    "        keras.layers.RandomRotation(0.05, fill_mode=\"constant\", seed=RANDOM_SEED),\n",
    "        keras.layers.RandomZoom(0.05, fill_mode=\"constant\", seed=RANDOM_SEED+1),\n",
    "        keras.layers.RandomContrast(0.1, seed=RANDOM_SEED+2),\n",
    "    ], name=\"simple_data_augmentation\")\n",
    "\n",
    "AUGMENTOR = get_simple_augmentation()\n",
    "\n",
    "def build_optimized_dataset(paths: List[str], labels: np.ndarray, training: bool, batch_size: int) -> tf.data.Dataset:\n",
    "    \"\"\"Optimized dataset building without caching\"\"\"\n",
    "    if len(paths) == 0:\n",
    "        raise ValueError(\"No paths provided for dataset building\")\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((tf.constant(paths), tf.constant(labels, dtype=tf.int32)))\n",
    "    \n",
    "    if training:\n",
    "        ds = ds.shuffle(min(SHUFFLE_BUFFER, len(paths)), seed=RANDOM_SEED, reshuffle_each_iteration=True)\n",
    "    \n",
    "    ds = ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.map(lambda img, label: (tf.ensure_shape(img, IMG_SIZE + (1,)), label),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if training:\n",
    "        ds = ds.repeat()\n",
    "        \n",
    "        def _apply_aug(img, label):\n",
    "            img_exp = tf.expand_dims(img, 0)\n",
    "            img_aug = AUGMENTOR(img_exp, training=True)\n",
    "            img_aug = tf.squeeze(img_aug, 0)\n",
    "            return img_aug, label\n",
    "        \n",
    "        ds = ds.map(_apply_aug, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# =========================\n",
    "# Model Loading\n",
    "# =========================\n",
    "def load_pretrained_model(model_path, num_classes):\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Pretrained model not found: {model_path}\")\n",
    "    \n",
    "    print(f\"📥 Loading pretrained model from: {model_path}\")\n",
    "    model = keras.models.load_model(model_path)\n",
    "    \n",
    "    # Check if the model output matches our number of classes\n",
    "    output_shape = model.output_shape\n",
    "    if output_shape and len(output_shape) > 1 and output_shape[-1] != num_classes:\n",
    "        print(f\"⚠️  Model output shape {output_shape[-1]} doesn't match number of classes {num_classes}\")\n",
    "        print(\"🔄 Replacing the final classification layer...\")\n",
    "        \n",
    "        # Remove the last layer\n",
    "        model = keras.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "        \n",
    "        # Add new classification layer\n",
    "        x = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"new_classification\")(model.output)\n",
    "        model = keras.Model(inputs=model.input, outputs=x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# Training Utils\n",
    "# =========================\n",
    "def get_optimizer():\n",
    "    # Increased learning rate for faster convergence\n",
    "    return keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "def get_advanced_callbacks():\n",
    "    return [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            BEST_MODEL_PATH, \n",
    "            monitor=\"val_accuracy\", \n",
    "            save_best_only=True, \n",
    "            mode=\"max\",\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_accuracy\", \n",
    "            patience=3,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.002,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", \n",
    "            factor=0.5, \n",
    "            patience=2,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "def compute_class_weights(y_train):\n",
    "    if len(y_train) == 0:\n",
    "        return {}\n",
    "    \n",
    "    class_counts = np.bincount(y_train)\n",
    "    total_samples = len(y_train)\n",
    "    num_classes = len(class_counts)\n",
    "    \n",
    "    # Handle zero counts\n",
    "    class_counts = np.where(class_counts == 0, 1, class_counts)\n",
    "    \n",
    "    class_weights = total_samples / (num_classes * class_counts.astype(float))\n",
    "    class_weights = class_weights / np.mean(class_weights)\n",
    "    \n",
    "    return {i: float(weight) for i, weight in enumerate(class_weights)}\n",
    "\n",
    "# =========================\n",
    "# Stratified Split\n",
    "# =========================\n",
    "def stratified_split(filepaths, labels, test_size=0.15, random_state=42):\n",
    "    \"\"\"Simple stratified split implementation without scikit-learn\"\"\"\n",
    "    if len(filepaths) == 0:\n",
    "        return [], [], np.array([]), np.array([])\n",
    "    \n",
    "    # Group by class\n",
    "    class_groups = defaultdict(list)\n",
    "    for path, label in zip(filepaths, labels):\n",
    "        class_groups[label].append(path)\n",
    "    \n",
    "    train_paths, val_paths = [], []\n",
    "    train_labels, val_labels = [], []\n",
    "    \n",
    "    for label, paths in class_groups.items():\n",
    "        n_val = max(1, int(len(paths) * test_size))\n",
    "        random.shuffle(paths)\n",
    "        \n",
    "        val_paths.extend(paths[:n_val])\n",
    "        train_paths.extend(paths[n_val:])\n",
    "        \n",
    "        val_labels.extend([label] * n_val)\n",
    "        train_labels.extend([label] * (len(paths) - n_val))\n",
    "    \n",
    "    # Shuffle the datasets\n",
    "    train_data = list(zip(train_paths, train_labels))\n",
    "    val_data = list(zip(val_paths, val_labels))\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(val_data)\n",
    "    \n",
    "    train_paths, train_labels = zip(*train_data) if train_data else ([], [])\n",
    "    val_paths, val_labels = zip(*val_data) if val_data else ([], [])\n",
    "    \n",
    "    return list(train_paths), list(val_paths), np.array(train_labels), np.array(val_labels)\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    set_all_seeds(RANDOM_SEED)\n",
    "    setup_gpu_memory()\n",
    "    \n",
    "    # Disable mixed precision for now to avoid issues\n",
    "    try:\n",
    "        from tensorflow.keras import mixed_precision\n",
    "        mixed_precision.set_global_policy('float32')\n",
    "        print(\"✅ Using float32 precision for stability\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(\"🔍 Checking dataset availability...\")\n",
    "    if not ensure_dataset_available():\n",
    "        print(\"❌ Dataset preparation failed. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"🔍 Scanning byclass dataset...\")\n",
    "    filepaths, labels, label2idx, idx2label, str_labels = scan_dataset_byclass(DATASET_DIR)\n",
    "    \n",
    "    if len(filepaths) == 0:\n",
    "        print(\"❌ No images found after extraction. Please check your archive file.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(filepaths)} images across {len(label2idx)} classes\")\n",
    "\n",
    "    # Print all classes with automatically detected characters\n",
    "    folder_to_char = print_all_classes_with_characters(label2idx, idx2label, str_labels)\n",
    "\n",
    "    # Use our custom stratified split\n",
    "    train_paths, val_paths, y_train, y_val = stratified_split(filepaths, labels, test_size=VAL_SPLIT, random_state=RANDOM_SEED)\n",
    "\n",
    "    if len(train_paths) == 0:\n",
    "        print(\"❌ No training data available after split\")\n",
    "        return\n",
    "\n",
    "    steps_per_epoch = max(1, len(train_paths) // BATCH_SIZE)\n",
    "    validation_steps = max(1, len(val_paths) // BATCH_SIZE)\n",
    "\n",
    "    class_weights = compute_class_weights(y_train)\n",
    "\n",
    "    print(\"📥 Loading or creating model...\")\n",
    "    try:\n",
    "        model = load_pretrained_model(PRETRAINED_MODEL, len(label2idx))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load pretrained model: {e}\")\n",
    "        print(\"🔄 Creating a new model...\")\n",
    "        # Create a simpler model if loading fails\n",
    "        inputs = keras.layers.Input(shape=IMG_SIZE + (1,))\n",
    "        x = keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "        x = keras.layers.MaxPooling2D(2)(x)\n",
    "        x = keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = keras.layers.MaxPooling2D(2)(x)\n",
    "        x = keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = keras.layers.Dropout(0.5)(x)\n",
    "        outputs = keras.layers.Dense(len(label2idx), activation=\"softmax\")(x)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(optimizer=get_optimizer(), \n",
    "                 loss=\"sparse_categorical_crossentropy\", \n",
    "                 metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    print(f\"\\n📊 Training samples: {len(train_paths)}\")\n",
    "    print(f\"📊 Validation samples: {len(val_paths)}\")\n",
    "    print(f\"📊 Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"📊 Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"📊 Learning rate: 0.001\")\n",
    "\n",
    "    print(\"\\n🚀 Starting training...\")\n",
    "    \n",
    "    # Build datasets\n",
    "    try:\n",
    "        ds_train = build_optimized_dataset(train_paths, y_train, training=True, batch_size=BATCH_SIZE)\n",
    "        ds_val = build_optimized_dataset(val_paths, y_val, training=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "        # Test one batch to ensure it works\n",
    "        print(\"Testing data pipeline...\")\n",
    "        for batch in ds_train.take(1):\n",
    "            print(f\"Batch shape: {batch[0].shape}, Labels shape: {batch[1].shape}\")\n",
    "            break\n",
    "\n",
    "        history = model.fit(\n",
    "            ds_train,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=ds_val,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_steps=validation_steps,\n",
    "            class_weight=class_weights,\n",
    "            callbacks=get_advanced_callbacks(),\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Analyze validation accuracy with the detected character mapping\n",
    "        analyze_validation_accuracy(history, model, val_paths, y_val, idx2label, folder_to_char)\n",
    "\n",
    "        print(f\"\\n✅ Training completed! Best model saved to: {BEST_MODEL_PATH}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Training failed with error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76402c9e-cf22-4578-93f6-6add6611b941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
